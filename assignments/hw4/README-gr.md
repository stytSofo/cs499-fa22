# Εργασία 4 (Ομαδική)

Προθεσμία Παράδοσης: 29 Νοεμβρίου 2022

Αυτή η εργασία αποτελείται από δύο μέρη. Αυτή είναι μια ομαδική εργασία που θα διεξαχθεί σε ομάδες των δύο φοιτητών/τριων.

## Μέρος 1: Κλιμάκωση Μικρουπηρεσιών Hotel Map

Σε αυτό το μέρος, θα κλιμακώσετε την εφαρμογή Hotel Map εκτελώντας πολλαπλά στιγμιότυπα μικροϋπηρεσιών σε μια συστοιχία. Μπορείτε να αναπτύξετε το Hotel Map Χάρτη ξενοδοχείου χρησιμοποιώντας είτε το Docker Swarm είτε το Kubernetes. Μπορείτε να χρησιμοποιήσετε είτε τις εικόνες κοντέινερ microservices που έχετε υλοποιήσει (από την εργασία 3) είτε αυτές που είναι διαθέσιμες από το DockerHub. Θα πρέπει να αξιολογήσετε τον τρόπο με τον οποίο η ρυθμαπόδοση (throughput) και η χρονική καθυστέρηση (latency) κλιμακώνονται με αυξανόμενο αριθμό στιγμιοτύπων μικροϋπηρεσιών. Μπορείτε να εστιάσετε σε μία μόνο μικρουπηρεσία της επιλογής σας (π.χ. αναζήτηση).

Μια μικρουπηρεσία μπορεί να έχει πολλαπλά στιγμιότυπα που εξυπηρετούν πολλά αιτήματα πελατών. Κάθε διακομιστής υποστήριξης έχει μια συγκεκριμένη χωρητικότητα. Η εξισορρόπηση φορτίου είναι το κλειδί για τη διανομή του φορτίου από τους πελάτες στα διαθέσιμα στιγμιότυπα. Η εξισορρόπηση φορτίου έχει πολλά πλεονεκτήματα και μερικά από αυτά είναι: (i) Ανοχή αποτυχιών: εάν ένα από τα αντίγραφά σας αποτύχει, τότε άλλοι διακομιστές μπορούν να εξυπηρετήσουν το αίτημα, (ii) Αυξημένη επεκτασιμότητα: μπορείτε να διανείμετε την κίνηση των χρηστών σε πολλούς διακομιστές αυξάνοντας την επεκτασιμότητα , (iii) Βελτιωμένη απόδοση: μπορείτε να βελτιώσετε τη διεκπεραίωση της εφαρμογής κατανέμοντας την κυκλοφορία σε διάφορους διακομιστές υποστήριξης και (iv) Μηδενικός χρόνος διακοπής: μπορείτε να επιτύχετε ανάπτυξη μηδενικού χρόνου διακοπής χρησιμοποιώντας τεχνικές κυλιόμενης ανάπτυξης.

Οι μικροϋπηρεσίες του Hotel Map χρησιμοποιούν gRPC για επικοινωνία με άλλες μικροϋπηρεσίες. Το gRPC είναι ένα από τα πιο δημοφιλή σύγχρονα πλαίσια RPC για επικοινωνία μεταξύ διεργασιών. Είναι μια εξαιρετική επιλογή για αρχιτεκτονική μικρουπηρεσιών. Οι υπηρεσίες Docker και Kubernetes παρέχουν Διευθύνσεις IP με ισορροπία φορτίου. Ωστόσο, αυτή η προεπιλεγμένη εξισορρόπηση φορτίου δεν λειτουργεί με το gRPC. Το gRPC λειτουργεί σε HTTP/2. Η σύνδεση TCP στο HTTP/2 είναι μακράς διάρκειας (long lived). Μια μεμονωμένη σύνδεση μπορεί να πολυπλέξει πολλαπλά αιτήματα. Αυτό μειώνει την επιβάρυνση που σχετίζεται με τη διαχείριση σύνδεσης. Αλλά σημαίνει επίσης ότι η εξισορρόπηση φορτίου σε επίπεδο σύνδεσης δεν είναι πολύ χρήσιμη. Η προεπιλεγμένη εξισορρόπηση φορτίου στο Docker Swarm και στο Kubernetes βασίζονται στην εξισορρόπηση φορτίου σε επίπεδο σύνδεσης. Για αυτόν τον λόγο, η προεπιλεγμένη εξισορρόπηση φορτίου δεν λειτουργεί με το gRPC.

Παρακάτω παρέχουμε συμβουλές για τον τρόπο χρήσης των δύο τύπων επιλογών εξισορρόπησης φορτίου που είναι διαθέσιμες σε gRPC, εξισορρόπηση μέσω διακομιστή μεσολάβησης (proxy load balancing) και εξισορρόπηση φοτίου από την πλευρά του πελάτη (client-side load balancing).

### Εξισορρόπηση μέσω διακομιστή μεσολάβησης

Στην εξισορρόπηση φόρτου διακομιστή μεσολάβησης, ο πελάτης εκδίδει κλήσεις RPC σε έναν διακομιστή μεσολάβησης εξισορρόπητης φόρτου (Load Balancer). Ο εξισορροπητής φόρτου διανέμει την κλήση RPC σε έναν από τους διαθέσιμους διακομιστές υποστήριξης που υλοποιούν την πραγματική λογική για την εξυπηρέτηση της κλήσης. Ο εξισορροπητής φόρτου παρακολουθεί το φορτίο σε κάθε στιγμιότυπο υποστήριξης και εφαρμόζει αλγόριθμους για δίκαιη κατανομή του φορτίου. Οι ίδιοι οι πελάτες δεν γνωρίζουν για τους διακομιστές υποστήριξης. Οι πελάτες μπορεί να είναι αναξιόπιστοι. Αυτή η αρχιτεκτονική χρησιμοποιείται συνήθως για υπηρεσίες που απευθύνονται στους χρήστες όπου οι πελάτες από ανοιχτό διαδίκτυο μπορούν να συνδεθούν με τους διακομιστές.

Τα πλεονεκτήματα και τα μειονεκτήματα της εξισορρόπησης φορτίου μεσολάβησης περιλαμβάνουν:
- Πλεονεκτήματα: Οι πελάτες δεν γνωρίζουν για στιγμιότυπα υποστήριξης
- Πλεονεκτήματα: Σας βοηθά να εργάζεστε με πελάτες όπου το εισερχόμενο φορτίο δεν είναι αξιόπιστο
- Μειονεκτήματα: Δεδομένου ότι ο εξισορροπητής φορτίου βρίσκεται στη διαδρομή δεδομένων, προκύπτει υψηλότερος λανθάνων χρόνος
- Μειονεκτήματα: Η απόδοση του εξισορροπητή φορτίου μπορεί να περιορίσει την επεκτασιμότητα

Μπορείτε να χρησιμοποιήσετε το NGINX ως διαμεσολαβητή gRPC και εξισορροπητή φόρτου εργασίας. Για παράδειγμα, θεωρήστε τη gRPC μικρουπηρεσία `profile` που ακούει στη θύρα `8081` που αναπτύσσεται χρησιμοποιώντας το Docker. Μπορείτε να δημιουργήσετε την υπηρεσία NGINX μέσω του `docker-compose.yml`:

```
services:

  profile:
    build: .
    image: ${REGISTRY-127.0.0.1:5000}/hotel_app_profile_single_node_memdb
    entrypoint: profile
    ports:
      - "8081"
    restart: always

  nginx:
    image: nginx:1.20.0
    container_name: nginx
    ports:
      - "8581:8581"
    volumes:
      - ./conf/nginx.conf:/etc/nginx/nginx.conf:ro

  ...
```

Η διαμόρφωση διακομιστή μεσολάβησης NGINX μοιάζει με:

```
upstream profile_server {
  server profile:8081;
}

server {
  listen 8581 http2;
  location / {
    grpc_pass grpc://profile_server;
  }
}
```

Αυτό που συμβαίνει εδώ είναι ότι ορίζουμε το NGINX για ακρόαση στη θύρα `8581` και διαμεσολάβηση αυτής της κυκλοφορίας HTTP2 στον διακομιστή μας gRPC που ορίζεται ως `profile_server`. Το NGINX βρίσκει ότι αυτός ο συνδυασμός `serviceName:port` επιλύεται σε περισσότερες από ένα στιγμιότυπο μέσω του Docker DNS. Το NGINX θα περιστρέφεται γύρω από αυτούς τους διακομιστές καθώς εισέρχονται τα αιτήματα. Υπάρχει ένας τρόπος να ρυθμίσετε τη συμπεριφορά εξισορρόπησης φορτίου για να κάνετε άλλα πράγματα, για τα οποία μπορείτε να μάθετε περισσότερα [εδώ](https://www.nginx.com/faq/what-are-the-load-balancing-algorithms-supported/).

Υπάρχουν μερικά αξιοσημείωτα πράγματα που συμβαίνουν στο αρχείο `docker-compose.yml`.

#### Αφήστε τους κοντέινερ σας να μεγαλώσουν

Βεβαιωθείτε ότι έχετε αφαιρέσει οποιοδήποτε `container_name` από μια υπηρεσία που θέλετε να κλιμακώσετε, διαφορετικά θα λάβετε μια προειδοποίηση.

Αυτό είναι σημαντικό επειδή το docker θα πρέπει να ονομάσει τα κοντέινερ σας μεμονωμένα όταν θέλετε να λειτουργούν περισσότερα από ένα από αυτά.

#### Να μην γίνεται σύγκρουση θυρών

Πρέπει να βεβαιωθούμε ότι εάν χαρτογραφείτε θύρες, χρησιμοποιείτε τη σωστή μορφή. Η τυπική αντιστοίχιση θύρας κεντρικού υπολογιστή σε σύντομη σύνταξη είναι "HOST:CONTAINER", η οποία θα οδηγήσει σε συγκρούσεις θυρών όταν προσπαθείτε να εκκινήσετε περισσότερα από ένα κοντέινερ του ιδίου τύπου. Αντ' αυτού θα χρησιμοποιήσουμε εφήμερες θύρες υπολογιστή.

Αντ' αυτού:

```
   ports:
     - "8081:8081"
```

Κάνε αυτό:

```
   ports:
     - "8581"
```     

Κάνοντας το με αυτόν τον τρόπο, το Docker θα αρπάξει αυτόματα τις αχρησιμοποίητες θύρες από τον υπολογιστή για να τις χαρτογραφήσει στο κοντέινερ και δεν θα ξέρετε ποιες είναι αυτές εκ των προτέρων. Μπορείτε να δείτε σε τι κατέληξαν αφού εκκινήσετε την υπηρεσία σας μέσω `
docker compose ps
`

#### Συνδέστε τον διακομιστή μεσολάβησης

Η χρήση της υπηρεσίας `nginx` στο `docker-compose.yml` συν το `nginx.conf` θα πρέπει να είναι το μόνο που χρειάζεστε εδώ. Απλώς βεβαιωθείτε ότι έχετε αντικαταστήσει το `profile:8081` με το όνομα και τη θύρα της υπηρεσίας σας, εάν διαφέρει από το παράδειγμα.

#### Εκκινήστε το

Αφού επεξεργαστείτε αυτά που περιγράφονται παραπάνω, ξεκινάτε τον διακομιστή μεσολάβησης και την υπηρεσία σας με έναν συγκεκριμένο αριθμό παρουσιών.

Για να κλιμακώσετε την υπηρεσία με το [Docker Swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/), εκτελείτε την ακόλουθη εντολή:

```
docker service scale profile=3
```

Για να κλιμακώσετε την υπηρεσία με Docker Compose, πρέπει να μεταβιβάσετε ένα πρόσθετο όρισμα `--scale <serviceName>:<number of instances>`.

```
docker-compose up --scale profile=3
```

#### Επιθεώρηση κοντέινερ

Μπορείτε να χρησιμοποιήσετε τη εύχρηστη εντολή `docker stats` για να δείτε στο τερματικό σας τα κοντέινερ σας. Αυτός είναι ένας ωραίος και γρήγορος τρόπος για να δείτε τη χρήση της CPU, της μνήμης και του δικτύου των κοντέινερ που τρέχουν, αλλά σας τα δείχνει ζωντανά χωρίς προβολή ιστορικού.

### Εξισορρόπηση φορτίου από την πλευρά του πελάτη

Στην εξισορρόπηση φορτίου από την πλευρά του πελάτη, ο πελάτης γνωρίζει πολλούς διακομιστές υποστήριξης και επιλέγει έναν προς χρήση για κάθε RPC. Εάν ο πελάτης επιθυμεί, μπορεί να εφαρμόσει τους αλγόριθμους εξισορρόπησης φορτίου με βάση την αναφορά φόρτωσης από τον διακομιστή. Για απλή ανάπτυξη, οι πελάτες μπορούν να περιστρέφουν αιτήματα μεταξύ των διαθέσιμων διακομιστών.

Μπορείτε να υλοποιήσετε εξισορρόπηση φόρτωσης από την πλευρά του πελάτη χρησιμοποιώντας την υπηρεσία χωρίς κεφαλή (headless service) στο Kubernetes. Αυτή η απλή εξισορρόπηση φορτίου λειτουργεί εύκολα με gRPC. Το μειονέκτημα είναι ότι δεν λαμβάνει υπόψη το φόρτο του διακομιστή.

#### Διαμόρφωση υπηρεσίας χωρίς κεφαλή

Ευτυχώς, το Kubernetes επιτρέπει στους πελάτες να ανακαλύπτουν τις διευθύνσεις IP των ομάδων (pod) μέσω αναζητήσεων DNS. Συνήθως, όταν εκτελείτε μια αναζήτηση DNS για μια υπηρεσία, ο διακομιστής DNS επιστρέφει μία μόνο IP — την IP της υπηρεσίας στη συστοιχία. Αλλά αν δηλώσετε στον Kubernetes ότι δεν χρειάζεστε IP συστοιχίας για την υπηρεσία σας (αυτό το κάνετε ορίζοντας το πεδίο ClusterIP σε `None` στις προδιαγραφές υπηρεσίας), ο διακομιστής DNS θα επιστρέψει τις διευθύνσεις IP των ομάδων (pod) αντί για την IP μεμονωμένης υπηρεσίας. Αντί να επιστρέψει μια μεμονωμένη εγγραφή DNS A, ο διακομιστής DNS θα επιστρέψει πολλές εγγραφές A για την υπηρεσία, καθεμία από τις οποίες δείχνει την IP ενός μεμονωμένου pod που υποστηρίζει την υπηρεσία εκείνη τη στιγμή. Επομένως, οι πελάτες μπορούν να κάνουν μια απλή αναζήτηση εγγραφών DNS και να λάβουν τις IP όλων των ομάδων (pod) που αποτελούν μέρος της υπηρεσίας. Στη συνέχεια, ο πελάτης μπορεί να χρησιμοποιήσει αυτές τις πληροφορίες για να συνδεθεί σε ένα, πολλά ή όλα. Η ρύθμιση του πεδίου ClusterIP σε μια προδιαγραφή υπηρεσίας σε None καθιστά την υπηρεσία ακέφαλη, καθώς ο Kubernetes δεν θα της εκχωρήσει μια IP συστοιχίας μέσω της οποίας οι πελάτες θα μπορούσαν να συνδεθούν με τις ομάδες (pods) που το υποστηρίζουν.

Για να μετατρέψετε μια υπηρεσία σε υπηρεσία χωρίς κεφαλή, το μόνο πεδίο που πρέπει να αλλάξετε είναι να ορίσετε το πεδίο `.spec.clusterIP` ως `None`.

#### Επαλήθευση DNS

Για να επιβεβαιώσετε το DNS της υπηρεσίας χωρίς κεφαλή, δημιουργήστε μια ομάδα (pod) με εικόνα [tutum/dnsutils](https://hub.docker.com/r/tutum/dnsutils) ως:

```
kubectl run dnsutils --image=tutum/dnsutils --command -- sleep infinity
```

και μετά εκτελέστε την εντολή

```
kubectl exec dnsutils --  nslookup grpc-server-service
```

Όπως μπορείτε να δείτε, η υπηρεσία υπηρεσίας χωρίς κεφαλή επιλύεται στη διεύθυνση IP όλων των ομάδων (pods) που συνδέονται μέσω της υπηρεσίας. 

#### Διαμόρφωση προγράμματος-πελάτη

Η μόνη αλλαγή που απομένει στην εφαρμογή πελάτη είναι να δείξετε την υπηρεσία χωρίς κεφαλή με τη θύρα των ομάδων (pods) διακομιστή.


## Μέρος 2: Υπηρεσίες Αποθήκευσης Δεδομένων

Επεκτείνετε τη μικροϋπηρεσία `rate` για αποθήκευση δεδομένων στο MongoDB και αποθήκευση δεδομένων με συχνή πρόσβαση στο Memcached.
Θα χρειαστεί να συμπληρώσετε κώδικα στο `docker-compose.yml`, `internal/rate/mongodb.go`, και επίσης να δημιουργήσετε (και να επεξεργαστείτε) τον αντίστοιχo protocol buffer.

Αξιολογήστε την απόδοση και τη ρυθμαπόδοση του λανθάνοντος χρόνου της υλοποίησης που βασίζεται στο MongoDB όταν αναπτύσσεται σε μεμονωμένα και πολλαπλά μηχανήματα.

Αξιολογήστε την απόδοση και τη ρυθμαπόδοση του λανθάνοντος χρόνου της υλοποίησης που βασίζεται σε Memcached όταν αναπτύσσεται σε μεμονωμένα και πολλαπλά μηχανήματα.

Συγκρίνετε την απόδοση της υλοποίησης MongoDB και των υλοποιήσεων που βασίζονται σε Memcached.

## Βαθμολόγηση

| Πρόβλημα   | Βαθμολογία |
|------------|--------|
| Q1         | 50     |
| Q2         | 60     |

### Υποβολή

Τώρα πρέπει να υποβάλετε την εργασία σας. Κάντε την αλλαγή σας και σπρώξτε την στο απομακρυσμένο αποθετήριο κάνοντας τα εξής:

```
$ git commit -am "[you fill me in]"
$ git push -u origin main
```

Μπορείτε να σπρώξετε τον κώδικα σας όσες φορές θέλετε, η βαθμολόγηση και ο χρόνος υποβολής θα βασιστούν στην τελευταία σας ώθηση.
